# ML-Final-Project
Machine Learning Final Project Nov. 2018 

INTRODUCTION

For our project, we are developing a system that creates filters that can be overlaid over human faces that cause facial recognition systems to be unable to detect the face. To do this, we will be using a generative adversarial network (GAN). GANs are 2 deep neural net systems, the generator and the discriminator, that are pitted against each other. These were first introduced by Ian Goodfellow and others in 2014, where this method was tested on the MNIST Dataset, the Toronto Face Database, and the CIFAR-10 Dataset. GANs will be discussed more in the Approach Section. To do this, we will use the Labeled Faces in the Wild Dataset, a dataset of over 13,000 face images with labels of the person’s name. Also, we will use a subset of the Caltech 101 Dataset, which contains 40-800 images for each classification.
For our approach, we will be using a “targeted attack” technique, that focuses on both ensuring that the filter and face will be classified as not a face while minimizing the actual effects of the filter to the human eye. To do this, we will develop a system that can 1) take in a human face label and face images, 2) read them and find a separate label with a good chance of being a viable label, and 3) develop a filter that when applied to the face and passed to the discriminator, will be read as not a face. To test this, we will be getting various face images, developing filters for them, and seeing how well they fare against our discriminator.

DATASET

For our project, we use 2 datasets. The first is the Labeled Faces in the Wild Dataset, which is over 13,000 images collected from the internet. Each image is labeled with the person’s name, and 1680 people have two separate pictures within the dataset. We specifically will be using the deep funneling set of images, which is a process that reduces variability from factors like posse or shadowing. Among the four augmented Labeled Faces in the Wild datasets, this one is tested as performing the best when it comes to facial recognition algorithms. The database was both created and updated by University of Massachusetts, Amherst Researchers, specifically, Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller. 
The other dataset we will use is the widely-used ImageNet, which contains more than a thousand classes of various objects. We will be using this dataset in order to be able to push classification of faces towards classification of a desired class. For instance, we will be overlay filters on faces such that the discriminator will classify it as a goldfish.

APPROACH

Our approach to create these filters is to develop a GAN, as we mentioned above. The idea is we are going to do something similar to a “targeted attack”, which is a technique used in GANs to get the discriminator to classify an image as a certain label. We are trying to do two things: 1) maximize the confidence of our random noise being classified as our targeted classification, and 2) minimize the difference between our face and filter and the original face. Below is an example of what we are trying to accomplish.
To do this, we need to develop a fooling system that can actually attack a certain classification. For this, we will be using the foolbox library, which helps to create adversarial examples against neural net systems. To do this, we will be calling upon the Foolbox library, specifically the LBFGSattack library. This uses limited-memory BFGS to minimize the differences between the face and the face and filter. This is done by optimizing the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm. This attack plus our face and the desired label we want it to fool, and we get an image back. This is our generated filter with our face. 
For our discriminator, we are using a deep convolutional neural network trained on ImageNet. Specifically, we will be using ResNet50. The ResNet50 is a residual network model, which is a deep neural network, that has 50 input nodes. We pass this to our foolbox as our model, and then use it to get predictions for the classifications of our generated face and filter. We then return this label and the confidence of it by the model. 
Finally, we go into our training. We will first take a batch of out photos, specifically half of them, add random noise filters over them, and then pass them to the discriminator. We then get the results over both the fake images and real images, and train on the generator based around some loss function. This is done for a defined very large number of sets (the cited link has the the epochs as 30000), so we need to install a save setting, saving our progress after a certain number of our steps above. 

